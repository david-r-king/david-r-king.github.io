---
layout: essay
type: essay
title: "AI - It's Pretty Good"
# All dates must be YYYY-MM-DD format!
date: 2025-12-13
published: true
labels:
  - AI
  - Final Project
  - Project Management
  - LLM
  - ChatGPT
  - TypeScript
---

<div class="text-center">
  <h2> AI In Programming </h2>
</div>

I have been a moderate user of AI for a couple of years now and found it to be very beneficial in ICS 314, with a caveat. It is very dependent on the details and prompts it's given, as my usage increased, so did my proficiency in prompt delivery. I noticed that most of the time it could execute the entire assignment or requirements, if given the proper information. On the flip side, if it is a rush project or time constraint there is a high chance it will not only fail to deliver, but make it very difficult to recover. All of my use of AI in this class came after I had at least an idea of what I was using it for. If I didn't, I would spend some time trying to learn concepts on my own. I gave my best effort to use it efficiently and not just let it do all my work, but there were times I was tired and/or lazy if I'm being fully transparent.

<div class="text-center">
  <h4> Experience WODs </h4>
</div>

These assignments were, for the most part, fairly straightforward and simple. I would usually watch the pre-recorded solution, then attempt it once on my own with minimal AI, then I would go full AI and see how well it compared. I would just send ChatGPT the screenshots as well as any additional information about the assignment and it would give a good starting point, if not complete the whole assignment in one attempt.

<div class="text-center">
  <h4> In-Class Practice WODs </h4>
</div>

Again, the early iterations of these assignment were solved fairly quickly by ChatGPT. I will say that as the difficulty progressed, I had to be more careful about what I was doing. I appreciated that because it forced me to pay more attention and understand certain overarching concepts like the file structure or a certain sequence of actions I needed to take. I was also grateful that we had these practice WODs before the actual WOD, because it helped us dial in any mistakes we might have made. At the end of the day, it circles back to AI is pretty good - but it is dependent on the competancy of the user.

<div class="text-center">
  <h4> In-Class WODs </h4>
</div>

These exercises were similar to the practice WODs, just more difficult. Having the practice experience helped us to understand the pros and cons of using AI. If we relied on it too much in practice, we might get lost. If we didn't use it enough, we might not have enough time to finish. For both of these experiences, I had a similar method as the at-home WOD assignments. I would send screenshots of the requirements, goals, and any additional highlights in the text body to ChatGPT. Once I had a response, depending on how much time was left, I would look through and see if it looks correct. Many times the LLM would do something unexpected, I found that if you directly tell it to not assume anything and ask about any areas of uncertainty, it would deliver much more efficiently.

<div class="text-center">
  <h4> Essays </h4>
</div>

I didn't use AI in the same way for the essays portion of this class as I did the coding. All the essays I wrote in this class had little to do with AI itself, I mostly used it if I was unsure of a concept or technology and the obvious spelling/grammar check. I think this is the most beneficial way to use it when in a learning environment since you can just have a conversation with it about anything. "Explain it to me like I'm 10" is a top-tier prompt for anyone trying to learn anything complex.

<div class="text-center">
  <h4> Final Project </h4>
</div>

This experience was similar to the WODs, just with a little more caution. With a team-based assignment, I didn't want to mess anything up for the other students. GitHub branches were a nice safety net to have. Using AI just required me to send it more information than the other assignments, due to multiple people working on it and it changing over time. 

<div class="text-center">
  <h4> Learning a Concept </h4>
</div>

I talked about this a little already, but I believe this is the most beneficial use of AI. Sure, it can spit out mediocre code in 30 seconds, so it does expedite time in that way. The real benefit of it would be having a lengthy conversation about something you're trying to learn. Everyone learns new things in a slightly different way, and being able to bounce the idea of how you think something works off of an "almost" person in private helps greatly. With its knowledge base being the whole internet, efficient/direct prompts, and a little time I think it can be a great teacher.

<div class="text-center">
  <h4> Answering or Asking a Question </h4>
</div>

I used ChatGPT for this a few times in a pretty straightforward way. Just ask the same question I was asked along with any context or background information. The difficulty with this is LLMs will almost always give you too much information, which congests my brain when I'm just looking for a one or two sentence answer.

<div class="text-center">
  <h4> Coding Examples/Explaining Code </h4>
</div>

I don't think I used it much to give specific examples. If I was working on an assignment while using AI, it would usually already have the full details of what I'm trying to accomplish. So from there I was able to point out anything it gave me and ask for a deeper explanation. 

<div class="text-center">
  <h4> Writing Code </h4>
</div>

I did use AI quite a bit to write code. Again, once I had an idea of what the goals were and how it should be done, I would send it all the same information I was given along with some guidance in the text body. Early on I noticed that without additional parameters or guidelines, it would assume things or do something it wasn't asked to do. I learned how to mitigate this, for the most part, by explicitly telling it not to assume anything and to ask about anything that might be unclear. Most of my usage was with ChatGPT, which I've heard isn't as good at writing code as some of the other LLMs. Even so, it does do a very good job if given all the same information you have. 

<div class="text-center">
  <h4> Quality Assurance </h4>
</div>

This is another really nice aspect of AI. I'm sure sending code errors to Google has been around for a long time, and LLM's are the next step in the evolution of that. Not only can it tell you what the error means, it will tell you exactly where it is and generate code in an attempt to fix it. Even though it doesn't always fix it with one punch, it's much more efficient than copying the error code into Google and looking through Stack Overflow or Reddit for an answer.

<div class="text-center">
  <h4> Conclusion </h4>
</div>

I think AI, if used properly, is an incredibly powerful tool in technical education. It's much like having a non-judgmental, always-available, subject matter expert in your pocket. I will often spend time just talking with it back and forth about something I'm trying to learn. While it's capabilities could be "abused" in the sense of doing all the work with minimal effort on the users side, I think it boils down to what the user wants. If the user doesn't care to learn the subject, it can mostly do the work if given clear prompts. On the other hand, if the user does have an interest in learning, it can hold your hand all the way to conceptual understanding. I appreciate that this class put a focus on the use of AI, as before I was unsure how the educational system felt about it. Openly being able to use it and talking about it in class helped educate me on how to use it, and how not to use it.


---
